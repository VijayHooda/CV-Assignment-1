# -*- coding: utf-8 -*-
"""Vijay_Q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U7ELhQOZ6jXTCyvPYBkYktqEiAL66pvG
"""

import wandb

wandb.login(relogin=True)

wandb.init(project="CV_assignment",name="1_q2")

import torch
import torch.utils.data as data
from torch.utils.data import DataLoader
import glob
import os
from PIL import Image
import re
from torchvision import transforms as T
from matplotlib import pyplot as plt
import numpy as np
import cv2
import random
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import pandas as pd
import openpyxl
import torch.nn as nn
import torchvision.models as models
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix

transform1 = T.Compose([T.ToTensor()])

if torch.cuda.is_available():
    device = torch.device("cuda")
    print("CUDA is available. Using GPU.")
else:
    device = torch.device("cpu")
    print("CUDA is not available. Using CPU.")

class_mapping = {
    "amur_leopard": 0,
    "amur_tiger": 1,
    "birds": 2,
    "black_bear": 3,
    "brown_bear": 4,
    "dog": 5,
    "roe_deer": 6,
    "sika_deer": 7,
    "wild_boar": 8,
    "people": 9,
}

Path = "/home/vijay/Dataset/aditya_test"

DataPath = os.path.join(Path,"data")

class_data_paths = os.listdir(DataPath)

class_data_paths

df = pd.DataFrame()

for clss in class_data_paths :
    c = os.listdir(os.path.join(DataPath,clss))
    c = [f"{DataPath}/{clss}/{path}" for path in c  ]
    class_df = pd.DataFrame({'Image_path' : c , 'Label' : class_mapping[clss], 'Class' : clss})
    df = pd.concat([df,class_df],ignore_index=True)

df.to_excel('data.xlsx',index=False,header=True)

a = pd.read_excel('data.xlsx')

a['Image_path'][0]

train_img , test_img_tmp , train_labels, test_labels_tmp = train_test_split(a['Image_path'],
                                                                     a['Label'],
                                                                     test_size=0.3,
                                                                     random_state=3)

train_df = pd.DataFrame({'Image_path' : train_img , 'Label' : train_labels})
train_df.to_excel('train_data.xlsx',index=False,header=True)

test_img, val_img,  test_labels ,  val_labels = train_test_split( test_img_tmp,
                                                                     test_labels_tmp,
                                                                     test_size=0.1,
                                                                     random_state=3)

test_df = pd.DataFrame({'Image_path' : test_img , 'Label' : test_labels})
test_df.to_excel('test_data.xlsx',index=False,header=True)

val_df = pd.DataFrame({'Image_path' : val_img , 'Label' : val_labels})
val_df.to_excel('val_data.xlsx',index=False,header=True)

train_class_dict = {key: 0 for key in class_mapping.values() }
test_class_dict = {key: 0 for key in class_mapping.values() }
val_class_dict = {key: 0 for key in class_mapping.values() }

for val in train_df['Label'] :
    train_class_dict[val] += 1

for val in test_df['Label'] :
    test_class_dict[val] += 1

for val in val_df['Label'] :
    val_class_dict[val] += 1

# Plotting
plt.figure(figsize=(10, 5))

plt.subplot(3, 1, 1)
plt.bar(train_class_dict.keys(), train_class_dict.values())
plt.title('Training Set Class Distribution')
plt.xlabel('Class Label')
plt.ylabel('Number of Samples')

plt.subplot(3, 1, 2)
plt.bar(test_class_dict.keys(), test_class_dict.values())
plt.title('Test Set Class Distribution')
plt.xlabel('Class Label')
plt.ylabel('Number of Samples')

plt.subplot(3, 1, 3)
plt.bar(val_class_dict.keys(), val_class_dict.values())
plt.title('Validation Set Class Distribution')
plt.xlabel('Class Label')
plt.ylabel('Number of Samples')

plt.tight_layout()
plt.show()

class dataloader(data.Dataset) :
    def __init__(self,data_xl):
        super(dataloader,self).__init__()
        self.data_img = []
        self.data_labels = []
        xl = pd.read_excel(data_xl)
        for i in range(xl.shape[0]) :
            self.data_img.append( xl['Image_path'][i] )
            self.data_labels.append( xl['Label'][i] )


    def __getitem__(self, index):
        img_path = self.data_img[index]
        img = Image.open(img_path).resize((224,224))
        timg = transform1(img)
        label = self.data_labels[index]

        return timg , label

    def __len__(self) :
        return len(self.data_img)

valPath = os.path.join(Path,"val_data.xlsx")

dval = dataloader(valPath)

data_val = DataLoader(dval,batch_size=1,shuffle=False)
i= 0
for batch in data_val :
    img , label = batch
    print(f"img shape : {img.shape} | label : {label}")
    i += 1
    if(i==10):
        break

class cnn_model(nn.Module):
    def __init__(self, num_classes):
        super(cnn_model, self).__init__()

        # Convolutional layers
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)

        # Max pooling layers
        self.maxpool1 = nn.MaxPool2d(kernel_size=4, stride=4)
        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)

        # Fully connected layer
        self.fc = nn.Linear(128 * 14 * 14, num_classes)  # Assuming input image size 224x224

        # Activation function
        self.relu = nn.ReLU()

    def forward(self, x):
        # Convolutional layers with ReLU activation
        x = self.relu(self.conv1(x))
        x = self.maxpool1(x)

        x = self.relu(self.conv2(x))
        x = self.maxpool2(x)

        x = self.relu(self.conv3(x))
        x = self.maxpool2(x)

        # Flatten the output
        x = x.view(x.size(0), -1)

        # Fully connected layer
        x = self.fc(x)
        return x

config = dict(
    epochs=10,
    classes=10,
    batch_size=32,
    lr=0.001,
)

config = wandb.config

epochs=10,
classes=10,
batch_size=32,
lr=0.001,

cnn_model = cnn_model(10)
cnn_model = cnn_model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)

trainPath = os.path.join(Path,"train_data.xlsx")
testPath = os.path.join(Path,"test_data.xlsx")
valPath = os.path.join(Path,"val_data.xlsx")

dtrain = dataloader(trainPath)
data_train = DataLoader(dtrain,batch_size=32,shuffle=True)

dtest = dataloader(testPath)
data_test = DataLoader(dtest,batch_size=32,shuffle=True)

dval = dataloader(valPath)
data_val = DataLoader(dval,batch_size=32,shuffle=False)

len(dtrain)

def get_output(model,img,label) :
    img = img.to(device)
    label = label.to(device)
    output = model(img)
    loss = criterion(output,label)
    return output,loss,img,label

def get_loss_accuracy(loss,correct,lent):
    tloss = loss/lent
    tacc = 100*correct/lent

    return tloss,tacc

for epoch in tqdm(range(epochs[0])) :
    cnn_model = cnn_model.train()
    train_loss_epoch = 0
    correct = 0
    val_loss = 0

    i=0
    for batch in data_train :
        optimizer.zero_grad()

        img , label = batch
        # print(img.size(0))
        # print(batch_size)

        output, loss , img , label = get_output(cnn_model,img,label)

        loss.backward()
        optimizer.step()
        i += 1
        train_loss_epoch += loss.item() /batch_size[0]
        _, predicted = torch.max(output, 1)
        predicted_dtr = predicted.to(device)
        correct += (predicted_dtr == label).sum().item()

    l = len(dtrain)
    train_loss , train_accuracy = get_loss_accuracy(train_loss_epoch,correct,l)

    cnn_model = cnn_model.eval()
    vald_loss = 0
    vald_correct = 0

    with torch.no_grad():
        iv = 0
        for batch in data_val :
            img_v , label_v = batch

            output_val , loss, img_v , label_v = get_output(cnn_model,img_v,label_v)
            iv += 1

            val_loss += loss.item()
            _, predicted = torch.max(output_val, 1)
            predicted_dv = predicted.to(device)
            vald_correct += (predicted_dv == label_v).sum().item()

    l_v = len(dval)
    val_loss , val_accuracy = get_loss_accuracy(val_loss,vald_correct,l_v)

    wandb.log({
    'epoch': epoch + 1,
    'train_loss': train_loss_epoch,
    'train_accuracy': train_accuracy,
    'val_loss': val_loss,
    'val_accuracy': val_accuracy
})

    print(f"Epoch : {epoch} | Train loss : {train_loss_epoch:.3f} | Train Acc : {train_accuracy:.3f} | Val acc. {val_accuracy:.2f}")


torch.save(cnn_model.state_dict(), os.path.join(Path,f"2_.pkl"))



# torch.onnx.export(
#             model,
#             images,
#             "part2.onnx",
#             input_names=["input"],
#             output_names=["output"],
#             dynamic_axes={
#                 "input": {0: "batch_size"},
#                 "output": {0: "batch_size"},
#             },
#         )
# wandb.save("part2.onnx")

# # Finish logging
# wandb.finish()

"""Testing the model"""

def get_output(model,img,label,to_test = False) :
    if to_test == False :
        img = img.to(device)
        label = label.to(device)
        output = model(img)
        loss = criterion(output,label)
        return output,loss,img,label
    else :
        img = img.to(device)
        label = label.to(device)
        output = model(img)
        return output,img,label

def test_log(true_labels,pred_labels):
    accuracy = accuracy_score(true_labels, pred_labels)
    f1 = f1_score(true_labels, pred_labels, average='macro')

    # Calculate confusion matrix
    conf_matrix = confusion_matrix(true_labels, pred_labels)

    # Log accuracy and F1-score to WandB
    wandb.log({'test_accuracy': accuracy, 'test_f1_score': f1})

    # Log confusion matrix to WandB
    wandb.log({"confusion_matrix": wandb.plot.confusion_matrix(probs=None,
                                                                y_true=np.array(true_labels),
                                                                preds=np.array(pred_labels),
                                                                class_names=[str(i) for i in range(10)])})

    return accuracy , f1

true_labels = []
pred_labels = []

cnn_model = cnn_model.eval()

with torch.no_grad():
    for batch in data_test:

        images, labels = batch
        outputs,images,labels = get_output(cnn_model,images,labels,to_test=True)

        _, predicted = torch.max(outputs, 1)

        true_labels.extend(labels.cpu().numpy())
        pred_labels.extend(predicted.cpu().numpy())


# Calculate accuracy and F1-score
acc , f1 = test_log(true_labels,pred_labels)

# Print accuracy and F1-score
print(f'Test Accuracy: {acc*100:.4f}')
print(f'Test F1-Score: {f1*100:.4f}')

class_miss_viz = {key: [] for key in class_mapping.values()}
class_miss_pred = {key: [] for key in class_mapping.values()}

cnn_model = cnn_model.eval()

data_test_viz = DataLoader(dtest,batch_size=1,shuffle=True)

i = 0
with torch.no_grad()  :
    for batch in data_test_viz :
        img , label = batch
        output,img,label = get_output(cnn_model,img,label,to_test=True)
        _, predicted = torch.max(output, 1)
        predicted_dtr = predicted.to(device)

        if(predicted.item() != label.item() and len(class_miss_viz[label.item()]) < 3 ) :
            class_miss_viz[label.item()].append(img.detach().cpu().numpy())
            class_miss_pred[label.item()].append(predicted.item())
            i += 1

        if(i == 30):
            break

len(class_miss_viz[0])

len(class_miss_pred[0])

class_miss_pred[0]







def display_misclassified_images(class_name, misclassified_images):
    plt.figure(figsize=(10, 5))
    plt.suptitle(f'Misclassified Images for Class {class_name}', fontsize=16)

    for i, image in enumerate(misclassified_images, 1):
        image = np.squeeze(image,axis=0)
        image = image.transpose((1, 2, 0))

        plt.subplot(1, 3, i)
        plt.imshow(image)
        plt.title(f'Predicted: {class_miss_pred[class_name][i-1]}')
        plt.axis('off')

    plt.show()

# Loop through each class and display misclassified images
for class_name, misclassified_images in class_miss_viz.items():
    display_misclassified_images(class_name, misclassified_images)

for key in class_miss_viz :
    for img in class_miss_viz[key] :

# Save the model in the exchangeable ONNX format
wandb.save(f"{Path}/2_.pkl")

# Finish logging
wandb.finish()

"""Fine tunning pretrained Resnet-18"""

wandb.init(project="CV_assignment_resnet18",name="1_q3_pretrained")

# trainPath = os.path.join(Path,"train_data.xlsx")
# testPath = os.path.join(Path,"test_data.xlsx")
# valPath = os.path.join(Path,"val_data.xlsx")

trainPath = '/home/vijay/Dataset/aditya_test/test_data.xlsx'
testPath = '/home/vijay/Dataset/aditya_test/test_data.xlsx'
valPath = '/home/vijay/Dataset/aditya_test/val_data.xlsx'


dtrain = dataloader(trainPath)
data_train = DataLoader(dtrain,batch_size=32,shuffle=True)

dtest = dataloader(testPath)
data_test = DataLoader(dtest,batch_size=32,shuffle=True)

dval = dataloader(valPath)
data_val = DataLoader(dval,batch_size=32,shuffle=False)

# pretrained_model = models.resnet18(pretrained=True)
pretrained_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)

for parameters in pretrained_model.parameters():
    parameters.requires_grad = False

pretrained_model.fc = nn.Linear(pretrained_model.fc.in_features, classes[0])

pretrained_model = pretrained_model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(pretrained_model.parameters(), lr=0.001)

for epoch in tqdm(range(epochs[0])):
    pretrained_model.train()
    train_loss_epoch = 0.0
    train_correct = 0

    i=0
    for batch in data_train:
        optimizer.zero_grad()
        images, labels = batch

        outputs, loss , images , labels = get_output(pretrained_model,images,labels)
        loss.backward()
        optimizer.step()
        i += 1
        train_loss_epoch += loss.item() / batch_size[0]
        _, predicted = torch.max(outputs, 1)
        train_correct += (predicted == labels).sum().item()

    # Calculate average training loss and accuracy
    l = len(dtrain)
    train_loss , train_accuracy = get_loss_accuracy(train_loss_epoch,train_correct,l)

    # Validation loop
    pretrained_model = pretrained_model.eval()
    val_loss = 0.0
    vald_correct = 0

    with torch.no_grad():
        iv = 0
        for batch in data_val :
            img_v , label_v = batch

            output_val , img_v , label_v = get_output(pretrained_model,img_v,label_v,to_test=True)
            iv += 1
            val_loss += loss.item() / batch_size[0]
            _, predicted = torch.max(output_val, 1)
            predicted_dv = predicted.to(device)
            vald_correct += (predicted_dv == label_v).sum().item()

    l_v = len(dval)
    val_loss , val_accuracy = get_loss_accuracy(val_loss,vald_correct,l_v)

    # Log training and validation metrics to WandB
    wandb.log({
    'epoch': epoch + 1,
    'train_loss': train_loss_epoch,
    'train_accuracy': train_accuracy,
    'val_loss': val_loss,
    'val_accuracy': val_accuracy
})

    # Print training and validation metrics
    print(f"Epoch : {epoch} | Train loss : {train_loss_epoch:.3f} | Train Acc : {train_accuracy:.3f} | Val acc. {val_accuracy:.2f}")

torch.save(pretrained_model.state_dict(), os.path.join("/home/vijay/Dataset/aditya_test",f"3_.pkl"))

wandb.finish()

wandb.init(project="CV_assignment_2_pretrained",name="test_result")

pretrained_model = models.resnet18()
pretrained_model.fc = nn.Linear(pretrained_model.fc.in_features, classes[0])
loaded_model = torch.load('/home/vijay/Dataset/aditya_test/3_.pkl')
pretrained_model.load_state_dict(loaded_model)

true_labels = []
pred_labels = []

pretrained_model = pretrained_model.to(device)
pretrained_model = pretrained_model.eval()

with torch.no_grad():
    for batch in data_test:

        images, labels = batch
        outputs,images,labels = get_output(pretrained_model,images,labels,to_test=True)

        _, predicted = torch.max(outputs, 1)

        true_labels.extend(labels.cpu().numpy())
        pred_labels.extend(predicted.cpu().numpy())


# Calculate accuracy and F1-score
acc , f1 = test_log(true_labels,pred_labels)

# Print accuracy and F1-score
print(f'Test Accuracy: {acc*100:.4f}')
print(f'Test F1-Score: {f1*100:.4f}')

from sklearn.manifold import TSNE

pretrained_model = pretrained_model.eval()

features = []
labels_f = []

with torch.no_grad() :
    for batch in data_train :
        images , labels = batch
        outputs,images,labels = get_output(pretrained_model,images,labels,to_test=True)
        out_np = outputs.cpu().numpy()
        label_np = labels.cpu().numpy()
        # features.extend(out_np)
        # labels_f.extend(label_np)
        features.append(out_np)
        labels_f.append(label_np)

    for batch in data_val :
        images , labels = batch
        outputs,images,labels = get_output(pretrained_model,images,labels,to_test=True)
        out_np = outputs.cpu().numpy()
        label_np = labels.cpu().numpy()
        # features.extend(out_np)
        # labels_f.extend(label_np)
        features.append(out_np)
        labels_f.append(label_np)

features = np.concatenate(features)
labels_f = np.concatenate(labels_f)


tsne = TSNE(n_components=2,random_state=3)
tsne1 = tsne.fit_transform(features)

import plotly.express as px

import plotly.express as px
import plotly.graph_objects as go

# Visualize t-SNE in 2D
tsne_df_2d = pd.DataFrame({'TSNE1': tsne1[:, 0], 'TSNE2': tsne1[:, 1], 'Label': labels_f})
tsne_df_2d.to_csv('2d_tsne.csv')

fig_2d = px.scatter(tsne_df_2d, x='TSNE1', y='TSNE2', color='Label', title='t-SNE Plot in 2D')
fig_2d.update_layout(title='t-SNE Plot in 2D')

# fig_2d.show()

# # Visualize t-SNE in 3D
tsne = TSNE(n_components=3, random_state=3)
tsne3 = tsne.fit_transform(features)

tsne_df_3d = pd.DataFrame({'TSNE1': tsne3[:, 0], 'TSNE2': tsne3[:, 1], 'TSNE3': tsne3[:, 2], 'Label': labels_f})
tsne_df_3d.to_csv('3d_tsne.csv')

fig_3d = go.Figure(data=[go.Scatter3d(x=tsne_df_3d['TSNE1'], y=tsne_df_3d['TSNE2'], z=tsne_df_3d['TSNE3'],
                                     mode='markers', marker=dict(size=5, color=tsne_df_3d['Label']))])
fig.update_traces(showlegend=True)
fig_3d.update_layout(title='t-SNE Plot in 3D')
# fig_3d.show()

tsne = TSNE(n_components=3, random_state=0)
X_tsne = tsne.fit_transform(embeds)

fig = px.scatter_3d(
    X_tsne, x=0, y=1, z=2,
    color=y,
    title='3D t-SNE Visualization'
)

fig.update_traces(marker=dict(size=5), showlegend=True)
fig.update_layout(
    width=1000,
    height=800
)

fig.show()

"""Data Augmentation"""

import albumentations as A

aug = A.Compose([
    A.VerticalFlip(p=0.5),
    A.RandomRotate90(p=0.5),
    A.HorizontalFlip(p=1),
    A.Transpose(p=1)
])

c = [f"{DataPath}/{clss}" for clss  in class_data_paths ]

c

def apply_augmentation_and_save(input_image_path, output_folder, num_augmentations=4):
    # Load the input image
    image = Image.open(input_image_path).resize((224,224))
    image = np.array(image)

    # Apply augmentations and save the images
    for i in range(num_augmentations):
        augmented = aug(image=image)
        augmented_image = augmented['image']

        t = input_image_path
        tr = re.split('[/.]',t)

        # Save the augmented image
        output_path = os.path.join(output_folder,f"aug_{tr[7]}_{i+1}.jpg")
        print(output_path)
        cv2.imwrite(output_path, augmented_image)

img_paths = pd.read_excel('data.xlsx')['Image_path']
t = img_paths[0]
tr = re.split('[/.]',t)
tr

tr[7]+'/.jpg'

tr[7]+'/.'+tr[8]

for path in img_paths :
    t = path
    tr = re.split('[/]',t)
    directory_path = os.path.join('/home/vijay/Dataset/aditya_test/aug_data',tr[6])
    if not os.path.exists(directory_path):
        os.makedirs(directory_path)
        print(f"Directory '{directory_path}' created.")

    apply_augmentation_and_save(path, directory_path)

aug_DataPath = os.path.join(Path,"aug_data")

class_data_paths = os.listdir(aug_DataPath)

class_data_paths

df = pd.DataFrame()

for clss in class_data_paths :
    c = os.listdir(os.path.join(aug_DataPath,clss))
    c = [f"{aug_DataPath}/{clss}/{path}" for path in c  ]
    class_df = pd.DataFrame({'Image_path' : c , 'Label' : class_mapping[clss], 'Class' : clss})
    df = pd.concat([df,class_df],ignore_index=True)

df.to_excel('aug_data.xlsx',index=False,header=True)

a = pd.read_excel('aug_data.xlsx')

a['Image_path'][0]

train_img , test_img_tmp , train_labels, test_labels_tmp = train_test_split(a['Image_path'],
                                                                     a['Label'],
                                                                     test_size=0.3,
                                                                     random_state=3)

train_aug_df = pd.DataFrame({'Image_path' : train_img , 'Label' : train_labels})
train_aug_df.to_excel('train_aug_data.xlsx',index=False,header=True)

test_img, val_img,  test_labels ,  val_labels = train_test_split( test_img_tmp,
                                                                     test_labels_tmp,
                                                                     test_size=0.1,
                                                                     random_state=3)

test_aug_df = pd.DataFrame({'Image_path' : test_img , 'Label' : test_labels})
test_aug_df.to_excel('test_aug_data.xlsx',index=False,header=True)

val_aug_df = pd.DataFrame({'Image_path' : val_img , 'Label' : val_labels})
val_aug_df.to_excel('val_aug_data.xlsx',index=False,header=True)

train_aug_class_dict = {key: 0 for key in class_mapping.values() }
test_aug_class_dict = {key: 0 for key in class_mapping.values() }
val_aug_class_dict = {key: 0 for key in class_mapping.values() }

for val in train_aug_df['Label'] :
    train_aug_class_dict[val] += 1

for val in test_aug_df['Label'] :
    test_aug_class_dict[val] += 1

for val in val_aug_df['Label'] :
    val_aug_class_dict[val] += 1

# Plotting
plt.figure(figsize=(10, 5))

plt.subplot(3, 1, 1)
plt.bar(train_aug_class_dict.keys(), train_aug_class_dict.values())
plt.title('Training Set Class Distribution')
plt.xlabel('Class Label')
plt.ylabel('Number of Samples')

plt.subplot(3, 1, 2)
plt.bar(test_aug_class_dict.keys(), test_aug_class_dict.values())
plt.title('Test Set Class Distribution')
plt.xlabel('Class Label')
plt.ylabel('Number of Samples')

plt.subplot(3, 1, 3)
plt.bar(val_aug_class_dict.keys(), val_aug_class_dict.values())
plt.title('Validation Set Class Distribution')
plt.xlabel('Class Label')
plt.ylabel('Number of Samples')

plt.tight_layout()
plt.show()

epochs=10,
classes=10,
batch_size=32,
lr=0.001,

trainPath = os.path.join(Path,"train_aug_data.xlsx")
testPath = os.path.join(Path,"test_aug_data.xlsx")
valPath = os.path.join(Path,"val_aug_data.xlsx")

dtrain = dataloader(trainPath)
data_train = DataLoader(dtrain,batch_size=32,shuffle=True)

dtest = dataloader(testPath)
data_test = DataLoader(dtest,batch_size=32,shuffle=True)

dval = dataloader(valPath)
data_val = DataLoader(dval,batch_size=32,shuffle=False)

wandb.init(project="CV_assignment_dataAug",name="1_q4_datAug")

for epoch in tqdm(range(epochs[0])):
    pretrained_model.train()
    train_loss_epoch = 0.0
    train_correct = 0

    i=0
    for batch in data_train:
        optimizer.zero_grad()
        images, labels = batch

        outputs, loss , images , labels = get_output(pretrained_model,images,labels)
        loss.backward()
        optimizer.step()
        i += 1
        train_loss_epoch += loss.item() / batch_size[0]
        _, predicted = torch.max(outputs, 1)
        train_correct += (predicted == labels).sum().item()

    # Calculate average training loss and accuracy
    l = len(dtrain)
    train_loss , train_accuracy = get_loss_accuracy(train_loss_epoch,train_correct,l)

    # Validation loop
    pretrained_model = pretrained_model.eval()
    val_loss = 0.0
    vald_correct = 0

    with torch.no_grad():
        iv = 0
        for batch in data_val :
            img_v , label_v = batch

            output_val , img_v , label_v = get_output(pretrained_model,img_v,label_v,to_test=True)
            iv += 1
            val_loss += loss.item() / batch_size[0]
            _, predicted = torch.max(output_val, 1)
            predicted_dv = predicted.to(device)
            vald_correct += (predicted_dv == label_v).sum().item()

    l_v = len(dval)
    val_loss , val_accuracy = get_loss_accuracy(val_loss,vald_correct,l_v)

    # Log training and validation metrics to WandB
    wandb.log({
    'epoch': epoch + 1,
    'train_loss': train_loss_epoch,
    'train_accuracy': train_accuracy,
    'val_loss': val_loss,
    'val_accuracy': val_accuracy
})

    # Print training and validation metrics
    print(f"Epoch : {epoch} | Train loss : {train_loss_epoch:.3f} | Train Acc : {train_accuracy:.3f} | Val acc. {val_accuracy:.2f}")

torch.save(pretrained_model.state_dict(), os.path.join("/home/vijay/Dataset/aditya_test",f"4_aug_.pkl"))

pretrained_model = models.resnet18()
pretrained_model.fc = nn.Linear(pretrained_model.fc.in_features, classes[0])
loaded_model = torch.load('/home/vijay/Dataset/aditya_test/4_aug_.pkl')
pretrained_model.load_state_dict(loaded_model)

true_labels = []
pred_labels = []

pretrained_model = pretrained_model.to(device)
pretrained_model = pretrained_model.eval()

with torch.no_grad():
    for batch in data_test:

        images, labels = batch
        outputs,images,labels = get_output(pretrained_model,images,labels,to_test=True)

        _, predicted = torch.max(outputs, 1)

        true_labels.extend(labels.cpu().numpy())
        pred_labels.extend(predicted.cpu().numpy())


# Calculate accuracy and F1-score
acc , f1 = test_log(true_labels,pred_labels)

# Print accuracy and F1-score
print(f'Test Accuracy: {acc*100:.4f}')
print(f'Test F1-Score: {f1*100:.4f}')

wandb.finish()

"""BONUS

For resnet model trained on augmented data :
"""

testPath = '/home/vijay/Dataset/aditya_test/test_data.xlsx'
dtest = dataloader(testPath)
data_test = DataLoader(dtest,batch_size=1,shuffle=True)

pretrained_model = models.resnet18()
pretrained_model.fc = nn.Linear(pretrained_model.fc.in_features, classes[0])
loaded_model = torch.load('/home/vijay/Dataset/aditya_test/4_aug_.pkl')
pretrained_model.load_state_dict(loaded_model)
pretrained_model = pretrained_model.eval()
pretrained_model = pretrained_model.to(device)

Path

class_feature = {key : [] for key in class_mapping.keys()}

class_feature

cp = os.listdir(f"{Path}/data")
with torch.no_grad():
    for p in tqdm(cp) :
        dir = f"{Path}/data/{p}"
        list = os.listdir(dir)

        for img in list :
            path = f"{dir}/{img}"
            img = Image.open(path).resize((224,224))
            img = transform1(img)
            label = class_mapping[p]

            output,images,labels = get_output(pretrained_model,images,labels,to_test=True)
            out_np = outputs.cpu().numpy()
            class_feature[p].append(out_np)

        features = np.concatenate(class_feature[p])
        fm = np.mean(class_feature[p],axis=0)
        class_feature[p] = fm

features = []
labels_f = []

with torch.no_grad() :
    for batch in data_test :
        images , labels = batch
        outputs,images,labels = get_output(pretrained_model,images,labels,to_test=True)
        out_np = outputs.cpu().numpy()
        label_np = labels.cpu().numpy()
        # features.extend(out_np)
        # labels_f.extend(label_np)
        features.append(out_np)
        labels_f.append(label_np)


features = np.concatenate(features)
features.shape

class_miss = {key: 0 for key in class_mapping.values()}

with torch.no_grad():
    for batch in data_test :
        img_v , label_v = batch
        output_val , img_v , label_v = get_output(pretrained_model,img_v,label_v,to_test=True)
        _, predicted = torch.max(output_val, 1)
        predicted_dv = predicted.to(device)

        if(label_v != predicted and class_miss[label_v.item()] !=3) :
            class_miss[label_v.item()] +=1
            euclidean_distance = np.linalg.norm(output_val.cpu() - class_feature[p])
            print(f"True class : {label_v[0]} | Predicted class : {predicted[0]} | Euclidean Distance : {euclidean_distance}")

        miss = class_miss.values()
        m = sum(miss)
        if(m == 30):
            break

"""
For cnn model :
"""

class CNN(nn.Module):
    def __init__(self, num_classes):
        super(CNN, self).__init__()

        # Convolutional layers
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)

        # Max pooling layers
        self.maxpool1 = nn.MaxPool2d(kernel_size=4, stride=4)
        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)

        # Fully connected layer
        self.fc = nn.Linear(128 * 14 * 14, num_classes)  # Assuming input image size 224x224

        # Activation function
        self.relu = nn.ReLU()

    def forward(self, x):
        # Convolutional layers with ReLU activation
        x = self.relu(self.conv1(x))
        x = self.maxpool1(x)

        x = self.relu(self.conv2(x))
        x = self.maxpool2(x)

        x = self.relu(self.conv3(x))
        x = self.maxpool2(x)

        # Flatten the output
        x = x.view(x.size(0), -1)

        # Fully connected layer
        x = self.fc(x)
        return x

cnn = CNN(10)
loaded_model = torch.load('/home/vijay/Dataset/aditya_test/2_.pkl')
cnn.load_state_dict(loaded_model)
cnn = cnn.eval()
cnn = cnn.to(device)

class_miss = {key: 0 for key in class_mapping.values()}

with torch.no_grad():
    for batch in data_test :
        img_v , label_v = batch
        output_val , img_v , label_v = get_output(cnn,img_v,label_v,to_test=True)
        _, predicted = torch.max(output_val, 1)
        predicted_dv = predicted.to(device)

        if(label_v != predicted and class_miss[label_v.item()] !=3) :
            class_miss[label_v.item()] +=1
            euclidean_distance = np.linalg.norm(output_val.cpu() - class_feature[p])
            print(f"True class : {label_v[0]} | Predicted class : {predicted[0]} | Euclidean Distance : {euclidean_distance}")

        miss = class_miss.values()
        m = sum(miss)
        if(m == 30):
            break

"""
For Resnet18 model :
"""

model = models.resnet18()
model.fc = nn.Linear(model.fc.in_features, classes[0])
loaded_model = torch.load('/home/vijay/Dataset/aditya_test/3_.pkl')
model.load_state_dict(loaded_model)
model = model.eval()
model = model.to(device)

class_miss = {key: 0 for key in class_mapping.values()}

with torch.no_grad():
    for batch in data_test :
        img_v , label_v = batch
        output_val , img_v , label_v = get_output(cnn_model,img_v,label_v,to_test=True)
        _, predicted = torch.max(output_val, 1)
        predicted_dv = predicted.to(device)

        if(label_v != predicted and class_miss[label_v.item()] !=3) :
            class_miss[label_v.item()] +=1
            euclidean_distance = np.linalg.norm(output_val.cpu() - class_feature[p])
            print(f"True class : {label_v[0]} | Predicted class : {predicted[0]} | Euclidean Distance : {euclidean_distance}")

        miss = class_miss.values()
        m = sum(miss)
        if(m == 30):
            break





