# -*- coding: utf-8 -*-
"""2_segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iQB6qU5GKmjvI4cywwtjj7h69x8T6-Zd
"""

import torch
import torch.utils.data as data
from torch.utils.data import DataLoader
import glob
import os
from PIL import Image
import re
from torchvision import transforms as T
from matplotlib import pyplot as plt
import numpy as np
import cv2
import random

import tqdm

if torch.cuda.is_available():
    device = torch.device("cuda")
    print("CUDA is available. Using GPU.")
else:
    device = torch.device("cpu")
    print("CUDA is not available. Using CPU.")

np.random.seed(4)

"""**Color mapping for IDD dataset** \
Reference : \
https://idd.insaan.iiit.ac.in/dataset/details/ \
https://github.com/AutoNUE/public-code/blob/master/helpers/anue_labels.py

"""

color_mapping = {
    0 : [128, 64,128],     # Road
    2: [244, 35,232],     # Sidewalk
    4: [220, 20, 60],   # Person/animal
    5: [255,  0,  0],   # Rider
    6: [0,  0,230],   # Motorcycle
    7: [119, 11, 32],   # bicycle

    9: [0,  0,142],     # Car
    10: [  0,  0, 70],  # Truck
    11: [0, 60,100],  # Bus
    12: [0, 80,100],  # Train/caravan/trailer (heavy vehicals)

    14: [102,102,156],     # Wall
    15: [190,153,153],     # Fence

    18: [220,220,  0],    # Traffic Sign
    19: [250,170, 30],    # Traffic Light
    20: [153,153,153],    # Pole
    22: [70, 70, 70],  # Building
    24: [107,142, 35],  # Vegetation
    25: [70,130,180],   # Sky
    255: [0, 0, 0]
}

f_path = "E:\Sem 6\CV\Assignment 1"

transform = T.Compose([
    T.ToTensor(),  # Converts the image to a tensor
])

torch.cuda.empty_cache()

img_folder = 'image_archive'
mask_folder = 'mask_archive'

"""**Dataloader**"""

class dataloader(data.Dataset) :
    def __init__(self,folder_path,to_test=False):
        super(dataloader,self).__init__()
        self.img_files = sorted(glob.glob(os.path.join(folder_path,'image_archive','*.jpg')))
        self.mask_files = sorted(glob.glob(os.path.join(folder_path,'mask_archive','*.jpg')))

        self.pixel_class =  [0,2,4,5,6,7,9,10,11,12,14,15,18,19,20,22,24,25]
        self.pixel_dict = {key: 0 for key in self.pixel_class}

        self.images = []
        self.masks = []
        self.indices = []

        if to_test == True :
            test_size = int(0.001*len(self.img_files))
            random.seed(4)
            self.indices = random.sample(range(len(self.img_files)), test_size)
            self.images = [self.img_files[i] for i in self.indices]
            self.masks = [self.mask_files[i] for i in self.indices]
        else :
            self.indices = np.arange(len(self.img_files)+1)
            self.images = self.img_files
            self.masks = self.mask_files


    # gives the og img, masked img and its corresponding id/index
    def __getitem__(self, index):
        img = self.images[index]
        mask = self.masks[index]

        data_img = Image.open(img).resize((512,512))
        data_tensor = transform(data_img)

        mask_img = Image.open(mask).resize((512,512))
        mask_tensor = transform(mask_img)

        return data_tensor, mask_tensor, self.indices[index]

    def __len__(self) :
        return len(self.images)

d = dataloader(f_path)
# d.create_test_split()

batch_size = 1
data_loader = DataLoader(d, batch_size=batch_size, shuffle=False)

it = 0

for batch in data_loader:
    data_img,mask_img, id = batch
    print(f"{data_img.size()} |  | {mask_img.size()} |  | {id[0]} ")
    print(f"file name : {d.img_files[id[0]]} " )

    it = it + 1
    if(it == 10):
        break

"""Data visualisation"""

def data_distri(d_loader):
    for mask in d_loader.mask_files :
        i = np.array(Image.open(mask).resize((512,512)))
        unique , counts = np.unique(i,return_counts=True)
        for i in range(unique.size) :
            if unique[i] in d_loader.pixel_dict.keys() :
                d_loader.pixel_dict[unique[i]] += counts[i]

    return

def data_distri_viz(d_loader) :
    plt.bar(d_loader.pixel_dict.keys(),d_loader.pixel_dict.values(),align='center',alpha=0.7)
    plt.title('Total Pixel counts vs Pixel class')
    plt.xlabel('Pixel Class')
    plt.ylabel('Pixel Count')
    plt.xticks(d_loader.pixel_class)
    plt.grid(True)
    plt.show()

data_distri(d)

data_distri_viz(d)

"""Randomly select and display two images from the dataset along with their masks"""

rv = np.random.randint(1,len(d.img_files)+1,size=2)

i1 = cv2.imread(d.img_files[rv[0]])
i1 = cv2.resize(i1, (512, 512))

# Load and resize the first mask
mi1 = cv2.imread(d.mask_files[rv[0]], cv2.IMREAD_GRAYSCALE)
mi1 = cv2.resize(mi1, (512, 512))
m1 = np.array(mi1)

colored_mask1 = np.zeros((m1.shape[0], m1.shape[1], 3), dtype=np.uint8)
for class_id, color in color_mapping.items():
    colored_mask1[m1 == class_id] = color

# Load and resize the second image
i2 = cv2.imread(d.img_files[rv[1]])
i2 = cv2.resize(i2, (512, 512))

# Load and resize the second mask
mi2 = cv2.imread(d.mask_files[rv[1]], cv2.IMREAD_GRAYSCALE)
mi2 = cv2.resize(mi2, (512, 512))
m2 = np.array(mi2)

colored_mask2 = np.zeros((m2.shape[0], m2.shape[1], 3), dtype=np.uint8)
for class_id, color in color_mapping.items():
    colored_mask2[m2 == class_id] = color

# Display the first image and its segmentation
cv2.imshow("Image 1", i1)
cv2.imshow("Segmentation 1", colored_mask1)
cv2.waitKey(0)
cv2.destroyAllWindows()

# Display the second image and its segmentation
cv2.imshow("Image 2", i2)
cv2.imshow("Segmentation 2", colored_mask2)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""**Loading pretrained DeepLabV3+**"""

from network import modeling
from datasets import Cityscapes

model = modeling.__dict__['deeplabv3plus_mobilenet'](num_classes=19, output_stride=16)
model.load_state_dict( torch.load( "best_deeplabv3plus_mobilenet_cityscapes_os16.pth" )['model_state']  )

dtest = dataloader(f_path,to_test=True)

batch_size = 1
test_data_loader = DataLoader(dtest, batch_size=batch_size, shuffle=False)

model = model.to(device)

transform2 = T.Compose([T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])

'''
This transformation was used before sending the images to the model in the AutoNUE paper
'''

def bw_color_mapping(c_img) :
    dummy_mask = np.ones((512, 512), dtype=np.uint8) * 255

    for key,value in color_mapping.items() :
        mask = np.all(c_img == value,axis=-1)
        np.putmask(dummy_mask, mask, key)

    return dummy_mask

test_indices = []
name_id_list = []

model = model.eval()

with torch.no_grad():
    for img in test_data_loader :
        data_img, mask_img, idx = img

        print(f"{idx} | index : {idx[0]} | file name : {dtest.img_files[idx]}")

        test_indices.append(idx)

        data_img = transform2(data_img)

        data_img = data_img.to(device)
        pred = model(data_img).max(1)[1].cpu().numpy()[0]
        print(f"pred shape : {pred.shape}")
        # pred_np = np.array(pred)
        # print(np.unique(pred_np))


        colorized_preds = Cityscapes.decode_target(pred).astype('uint8')
        colorized_preds = Image.fromarray(colorized_preds)
        colorized_preds = np.array(colorized_preds)
        # print(f"cp : {colorized_preds.shape}")

        pred = bw_color_mapping(colorized_preds)
        pred_np = np.array(pred)
        print(np.unique(pred_np))


        name = dtest.img_files[idx]
        name_id = re.split('[_.]',name)[-2]
        name_id_list.append(name_id)

        path1_bw = os.path.join('val_predictions_bw',f'pred_mask_{name_id}_bw.jpg')
        path2 = os.path.join('val_predictions',f'pred_mask_{name_id}.jpg')

        cv2.imwrite(path1_bw,pred_np)

        cv2.imwrite(path2,colorized_preds)
        # colorized_preds.save(os.path.join('val_predictions',f'pred_mask_{idx[0]}.jpg'))

name_id_list

"""To visualize original image, original masks"""

val_preds = sorted(glob.glob(os.path.join('val_predictions','*.jpg')))
val_preds_bw = sorted(glob.glob(os.path.join('val_predictions_bw','*.jpg')))
val_preds_bw

all_pred_files = os.listdir('val_predictions')
all_pred_files

p = dtest.img_files[test_indices[0].item()]
pres = re.split('[_.]',p)
pres[-2]

for id in all_pred_files :
    if pres[-2] in id :
        print('found')
        print(id)

val_predictions = []
val_predictions_bw = []

for i in range(len(test_indices)):

    img_id = re.split('[_.]',dtest.img_files[test_indices[i].item()])[-2]

    corresponding_val_pred = 'val_predictions'
    # corresponding_val_pred_bw = 'val_predictions_bw'

    for val_pred_file_name in all_pred_files :
        if img_id in val_pred_file_name :
            corresponding_val_pred = os.path.join(corresponding_val_pred,val_pred_file_name)
            # corresponding_val_pred_bw = os.path.join(corresponding_val_pred_bw,val_pred_file_name,)
            val_predictions.append(corresponding_val_pred)
            # val_predictions_bw.append(corresponding_val_pred_bw)


    print(corresponding_val_pred)


    i1 = cv2.imread(dtest.img_files[test_indices[i]])
    i1 = cv2.resize(i1, (512, 512))

    # Load and resize the first mask
    mi1 = cv2.imread(dtest.mask_files[test_indices[i]], cv2.IMREAD_GRAYSCALE)
    mi1 = cv2.resize(mi1, (512, 512))
    m1 = np.array(mi1)

    colored_mask1 = np.zeros((m1.shape[0], m1.shape[1], 3), dtype=np.uint8)
    for class_id, color in color_mapping.items():
        colored_mask1[m1 == class_id] = color


    p1 = cv2.imread(corresponding_val_pred)
    print(type(p1))
    p1 = cv2.resize(p1,(512,512))


    # Display the first image and its segmentation
    cv2.imshow("Image ", i1)
    cv2.imshow("Mask Label ", colored_mask1)
    cv2.imshow("Predicted Mask", p1)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

"""Creating colored masks for all the files and saving it"""

masks = os.listdir('mask_archive')
for mask in masks :
    print(mask)
    m = cv2.imread(f'mask_archive\{mask}',cv2.IMREAD_GRAYSCALE)
    m = cv2.resize(m,(512,512))
    m_arr = np.array(m)

    colored_mask = np.zeros((m.shape[0], m.shape[1], 3), dtype=np.uint8)
    for class_id, color in color_mapping.items():
        colored_mask[m == class_id] = color

    cv2.imwrite(f'mask_coloured_archive\{mask}.jpg',colored_mask)

"""**Classwise performance**

1) Pixel Accuracy
"""

pred_mask = []
og_mask = []

for i in name_id_list :
    pmask = ''
    omask = ''

    for val_pred_mask_name in val_preds_bw :
        if i in val_pred_mask_name :
            pmask=val_pred_mask_name

    for og_mask_name in dtest.mask_files :
        if i in og_mask_name:
            omask = og_mask_name

    # print(pmask)
    # print(omask)

    ip = cv2.imread(pmask,cv2.IMREAD_GRAYSCALE)
    ip = cv2.resize(ip,(512,512))
    parr = np.array(ip)

    pred_mask.append(parr)

    io = cv2.imread(omask,cv2.IMREAD_GRAYSCALE)
    io = cv2.resize(io,(512,512))
    oarr = np.array(io)

    og_mask.append(oarr)

pred_mask = np.stack(pred_mask)
og_mask = np.stack(og_mask)

classes =  [0,2,4,5,6,7,9,10,11,12,14,15,18,19,20,22,24,25]
class_dict = {key: 0 for key in classes}

# def accuracy(groundtruth_mask, pred_mask):
#     intersect = np.sum(pred_mask*groundtruth_mask)
#     union = np.sum(pred_mask) + np.sum(groundtruth_mask) - intersect
#     xor = np.sum(groundtruth_mask==pred_mask)
#     acc = np.mean(xor/(union + xor - intersect))
#     return round(acc, 3)

def accuracy(groundtruth_mask, pred_mask):
    intersect = np.sum(pred_mask * groundtruth_mask)
    union = np.sum(np.subtract(np.add(pred_mask, groundtruth_mask), intersect))
    xor = np.sum(groundtruth_mask == pred_mask)
    acc = np.mean(xor / (union + xor - intersect))
    return round(acc, 3)

accuracy(pred_mask[0].flatten(),og_mask[0].flatten())

for i in range(len(pred_mask)) :
    p_nparray = np.array(pred_mask[i]).flatten()
    o_nparray = np.array(og_mask[i]).flatten()
    for key in class_dict.keys() :
        p = (p_nparray == key )
        # p = np.stack(p)
        o = (o_nparray == key )
        # p = np.stack(p)

        c_acc = np.sum(p == o)

        class_dict[key] += c_acc/len(pred_mask) * 100

p.sum()

for key in class_dict :
    print(f"{key} : {class_dict[key]}")

keys = class_dict.keys()
values = class_dict.values()
# Plotting
plt.bar(keys, values)
plt.xlabel('Keys')
plt.ylabel('Values')
plt.title('Key vs Value Graph')
plt.show()

"""Dice Coefficient"""

classes =  [0,2,4,5,6,7,9,10,11,12,14,15,18,19,20,22,24,25]
class_dict = {key: 0 for key in classes}

for i in range(len(pred_mask)) :
    p_nparray = np.array(pred_mask[i]).flatten()
    o_nparray = np.array(og_mask[i]).flatten()

    for key in class_dict :
        p = (p_nparray == key )
        o = (o_nparray == key )

        intersection = np.logical_and(o,p).sum()
        union = np.logical_or(o,p).sum()
        dice_coefficient = (2.0 * intersection) / (union + 1e-8)
        dice_coefficient = dice_coefficient
        class_dict[key] += dice_coefficient/len(pred_mask)

for key in class_dict :
    print(f"{key} : {class_dict[key]}")

keys = class_dict.keys()
values = class_dict.values()
# Plotting
plt.bar(keys, values)
plt.xlabel('Keys')
plt.ylabel('Values')
plt.title('Key vs Value Graph')
plt.show()

"""IOU"""

classes =  [0,2,4,5,6,7,9,10,11,12,14,15,18,19,20,22,24,25]
class_dict = {key: 0 for key in classes}

for i in range(len(pred_mask)) :
    p_nparray = np.array(pred_mask[i]).flatten()
    o_nparray = np.array(og_mask[i]).flatten()

    for key in class_dict :
        p = (p_nparray == key )
        o = (o_nparray == key )

        intersection = np.logical_and(o,p).sum()
        # print(intersection)
        union = np.logical_or(o,p).sum()
        iou = intersection / (union + 1e-8)

        class_dict[key] += iou/len(pred_mask)

for key in class_dict :
    print(f"{key} : {class_dict[key]}")

keys = class_dict.keys()
values = class_dict.values()
# Plotting
plt.bar(keys, values)
plt.xlabel('Keys')
plt.ylabel('Values')
plt.title('Key vs Value Graph')
plt.show()

"""Metrics ver 2.0"""

classes =  [0,2,4,5,6,7,9,10,11,12,14,15,18,19,20,22,24,25]
tp = {key: 0 for key in classes}
tn = {key: 0 for key in classes}
fp = {key: 0 for key in classes}
fn = {key: 0 for key in classes}

from tqdm import tqdm

for i in tqdm(range(len(pred_mask))):
    pred = pred_mask[i]
    act_mask = og_mask[i]

    pred = np.asarray(pred)
    pred.flatten()

    act_mask = np.asarray(act_mask)
    act_mask.flatten()

    for key in tp:
        tp[key] += sum((pred[act_mask == key] == key) == True)
        tn[key] += sum((pred[act_mask != key] != key) == True)
        fp[key] += sum((act_mask[pred == key] != key) == True)
        fn[key] += sum((pred[act_mask == key] != key) == True)

tp[2]/(tp[2]+fn[2])

tn

fp

fn

"""Class wise pixel accuracy"""

for key in tn.keys() :
    print(f"accuracy for class {key} : {(tp[key]+tn[key])/(tp[key]+fn[key]+fp[key]+tn[key])}")

"""class wise precision"""

for key in tn.keys() :
    print(f"precision for class {key} : {(tp[key])/(tp[key]+fp[key])}")

"""class wise recall"""

for key in tn.keys() :
    print(f"precision for class {key} : {(tp[key])/(tp[key]+fn[key])}")

"""class wise iou"""

for key in tn.keys() :
    print(f"iou for class {key} : {(tp[key])/(tp[key]+fp[key]+fn[key])}")

"""confusion matrix"""

import seaborn as sns

for key in tn.keys():
    cmat = [[tp[key], fn[key]], [fp[key], tn[key]]]
    plt.figure(figsize = (3,3))
    sns.heatmap(cmat/np.sum(cmat), cmap="Reds", annot=True, fmt = '.2%', square=1,   linewidth=2.)
    plt.title(f"CMAT. for class {key}")
    plt.xlabel("predictions")
    plt.ylabel("real values")
    plt.show()





"""On Cityscapes Val set"""

im = 'cityscapes_val\1.jpg'

from PIL import Image
import numpy as np

# Load the image
img_path = 'cityscapes_val/1.jpg'  # Replace with the path to your 16-bit image
image = Image.open(img_path)

# Convert the image to a NumPy array
img_array = np.array(image)
# print(img_array.shape)

# Get the dimensions of the image
height, width = img_array.shape[:-1]

# Split the image in half horizontally
half_width = width // 2
img = img_array[:, :half_width]
mask = img_array[:, half_width:]

# Save the halves as new images
Image.fromarray(img).save('first_half.jpg')
Image.fromarray(mask).save('second_half.jpg')

city_val = os.listdir('cityscapes_val')
city_val

i = 1

for path in city_val :
    img_path = path  # Replace with the path to your 16-bit image
    image = Image.open(f'cityscapes_val/{img_path}')

    # Convert the image to a NumPy array
    img_array = np.array(image)
    # print(img_array.shape)

    # Get the dimensions of the image
    height, width = img_array.shape[:-1]

    # Split the image in half horizontally
    half_width = width // 2
    img = img_array[:, :half_width]
    mask = img_array[:, half_width:]

    # Save the halves as new images
    Image.fromarray(img).save(f'cityscapes_final\image_archive\image_{i}.jpg')
    Image.fromarray(mask).save(f'cityscapes_final\mask_archive\mask_{i}.jpg')
    i += 1

dcity = dataloader('cityscapes_final')

city_val = DataLoader(dcity,batch_size=1,shuffle=True)

t = 0
for batch in city_val :
    img , mask , idx = batch
    print(f"image shape : {img.shape} | mask shape : {mask.shape} | index : {idx}")
    t += 1
    if(t==10):
        break

test_indices = []
name_id_list = []

model = model.eval()

with torch.no_grad():
    for img in city_val :
        data_img, mask_img, idx = img

        print(f"{idx} | index : {idx[0]} | file name : {dtest.img_files[idx]}")

        test_indices.append(idx)

        data_img = transform2(data_img)

        data_img = data_img.to(device)
        pred = model(data_img).max(1)[1].cpu().numpy()[0]
        print(f"pred shape : {pred.shape}")
        # pred_np = np.array(pred)
        # print(np.unique(pred_np))


        colorized_preds = Cityscapes.decode_target(pred).astype('uint8')
        colorized_preds = Image.fromarray(colorized_preds)
        colorized_preds = np.array(colorized_preds)
        # print(f"cp : {colorized_preds.shape}")

        pred = bw_color_mapping(colorized_preds)
        pred_np = np.array(pred)
        print(np.unique(pred_np))


        name = dtest.img_files[idx]
        name_id = re.split('[_.]',name)[-2]
        name_id_list.append(name_id)

        path1_bw = os.path.join('cityscapes_final\city_pred_bw',f'city_mask_{name_id}_bw.jpg')
        path2 = os.path.join('cityscapes_final\city_pred_color',f'city_mask_{name_id}.jpg')

        cv2.imwrite(path1_bw,pred_np)

        cv2.imwrite(path2,colorized_preds)
        # colorized_preds.save(os.path.join('val_predictions',f'pred_mask_{idx[0]}.jpg'))





